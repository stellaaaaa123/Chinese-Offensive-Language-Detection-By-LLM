{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.354480052321779,
  "eval_steps": 500,
  "global_step": 900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013080444735120994,
      "grad_norm": 2.4641852378845215,
      "learning_rate": 4.9997651591020244e-05,
      "loss": 0.7101,
      "step": 5
    },
    {
      "epoch": 0.026160889470241987,
      "grad_norm": 1.718550682067871,
      "learning_rate": 4.999060680528294e-05,
      "loss": 0.4146,
      "step": 10
    },
    {
      "epoch": 0.03924133420536298,
      "grad_norm": 0.6003979444503784,
      "learning_rate": 4.997886696631114e-05,
      "loss": 0.2169,
      "step": 15
    },
    {
      "epoch": 0.052321778940483975,
      "grad_norm": 0.897948682308197,
      "learning_rate": 4.9962434279700316e-05,
      "loss": 0.1799,
      "step": 20
    },
    {
      "epoch": 0.06540222367560497,
      "grad_norm": 0.7000919580459595,
      "learning_rate": 4.9941311832703954e-05,
      "loss": 0.1591,
      "step": 25
    },
    {
      "epoch": 0.07848266841072596,
      "grad_norm": 0.44485726952552795,
      "learning_rate": 4.99155035936536e-05,
      "loss": 0.1382,
      "step": 30
    },
    {
      "epoch": 0.09156311314584696,
      "grad_norm": 0.5147438049316406,
      "learning_rate": 4.9885014411213285e-05,
      "loss": 0.1517,
      "step": 35
    },
    {
      "epoch": 0.10464355788096795,
      "grad_norm": 0.35332342982292175,
      "learning_rate": 4.9849850013468585e-05,
      "loss": 0.1355,
      "step": 40
    },
    {
      "epoch": 0.11772400261608895,
      "grad_norm": 0.688642144203186,
      "learning_rate": 4.98100170068505e-05,
      "loss": 0.1387,
      "step": 45
    },
    {
      "epoch": 0.13080444735120994,
      "grad_norm": 0.3645465075969696,
      "learning_rate": 4.976552287489426e-05,
      "loss": 0.1328,
      "step": 50
    },
    {
      "epoch": 0.14388489208633093,
      "grad_norm": 0.20637714862823486,
      "learning_rate": 4.9716375976833396e-05,
      "loss": 0.1323,
      "step": 55
    },
    {
      "epoch": 0.15696533682145192,
      "grad_norm": 0.4307744801044464,
      "learning_rate": 4.9662585546029246e-05,
      "loss": 0.1285,
      "step": 60
    },
    {
      "epoch": 0.17004578155657293,
      "grad_norm": 0.4390839636325836,
      "learning_rate": 4.960416168823626e-05,
      "loss": 0.1167,
      "step": 65
    },
    {
      "epoch": 0.18312622629169392,
      "grad_norm": 0.22305217385292053,
      "learning_rate": 4.954111537970342e-05,
      "loss": 0.1226,
      "step": 70
    },
    {
      "epoch": 0.1962066710268149,
      "grad_norm": 0.2295156717300415,
      "learning_rate": 4.94734584651121e-05,
      "loss": 0.1256,
      "step": 75
    },
    {
      "epoch": 0.2092871157619359,
      "grad_norm": 0.2142115980386734,
      "learning_rate": 4.9401203655350766e-05,
      "loss": 0.1164,
      "step": 80
    },
    {
      "epoch": 0.2223675604970569,
      "grad_norm": 0.15580588579177856,
      "learning_rate": 4.932436452512693e-05,
      "loss": 0.118,
      "step": 85
    },
    {
      "epoch": 0.2354480052321779,
      "grad_norm": 0.17289364337921143,
      "learning_rate": 4.9242955510416877e-05,
      "loss": 0.121,
      "step": 90
    },
    {
      "epoch": 0.2485284499672989,
      "grad_norm": 0.3245212137699127,
      "learning_rate": 4.915699190575349e-05,
      "loss": 0.1159,
      "step": 95
    },
    {
      "epoch": 0.2616088947024199,
      "grad_norm": 0.23737257719039917,
      "learning_rate": 4.906648986135287e-05,
      "loss": 0.1173,
      "step": 100
    },
    {
      "epoch": 0.27468933943754087,
      "grad_norm": 0.25789546966552734,
      "learning_rate": 4.897146638008012e-05,
      "loss": 0.1107,
      "step": 105
    },
    {
      "epoch": 0.28776978417266186,
      "grad_norm": 0.3282765746116638,
      "learning_rate": 4.8871939314254965e-05,
      "loss": 0.113,
      "step": 110
    },
    {
      "epoch": 0.30085022890778285,
      "grad_norm": 0.21785739064216614,
      "learning_rate": 4.8767927362297816e-05,
      "loss": 0.1061,
      "step": 115
    },
    {
      "epoch": 0.31393067364290383,
      "grad_norm": 0.1700374186038971,
      "learning_rate": 4.865945006521684e-05,
      "loss": 0.1093,
      "step": 120
    },
    {
      "epoch": 0.3270111183780249,
      "grad_norm": 0.3918374180793762,
      "learning_rate": 4.854652780293672e-05,
      "loss": 0.1012,
      "step": 125
    },
    {
      "epoch": 0.34009156311314587,
      "grad_norm": 0.21547585725784302,
      "learning_rate": 4.8429181790469824e-05,
      "loss": 0.1131,
      "step": 130
    },
    {
      "epoch": 0.35317200784826686,
      "grad_norm": 0.5224208235740662,
      "learning_rate": 4.830743407393051e-05,
      "loss": 0.104,
      "step": 135
    },
    {
      "epoch": 0.36625245258338784,
      "grad_norm": 0.34845462441444397,
      "learning_rate": 4.818130752639326e-05,
      "loss": 0.1201,
      "step": 140
    },
    {
      "epoch": 0.37933289731850883,
      "grad_norm": 0.18411153554916382,
      "learning_rate": 4.8050825843595395e-05,
      "loss": 0.1024,
      "step": 145
    },
    {
      "epoch": 0.3924133420536298,
      "grad_norm": 0.3066384494304657,
      "learning_rate": 4.791601353948537e-05,
      "loss": 0.1066,
      "step": 150
    },
    {
      "epoch": 0.4054937867887508,
      "grad_norm": 0.20045706629753113,
      "learning_rate": 4.777689594161724e-05,
      "loss": 0.1118,
      "step": 155
    },
    {
      "epoch": 0.4185742315238718,
      "grad_norm": 0.22516608238220215,
      "learning_rate": 4.763349918639227e-05,
      "loss": 0.1001,
      "step": 160
    },
    {
      "epoch": 0.4316546762589928,
      "grad_norm": 0.2128668576478958,
      "learning_rate": 4.748585021414869e-05,
      "loss": 0.1017,
      "step": 165
    },
    {
      "epoch": 0.4447351209941138,
      "grad_norm": 0.572289764881134,
      "learning_rate": 4.7333976764100275e-05,
      "loss": 0.112,
      "step": 170
    },
    {
      "epoch": 0.4578155657292348,
      "grad_norm": 0.3233823776245117,
      "learning_rate": 4.717790736912493e-05,
      "loss": 0.0942,
      "step": 175
    },
    {
      "epoch": 0.4708960104643558,
      "grad_norm": 0.33535900712013245,
      "learning_rate": 4.701767135040414e-05,
      "loss": 0.1132,
      "step": 180
    },
    {
      "epoch": 0.4839764551994768,
      "grad_norm": 0.698578417301178,
      "learning_rate": 4.685329881191436e-05,
      "loss": 0.1017,
      "step": 185
    },
    {
      "epoch": 0.4970568999345978,
      "grad_norm": 0.29608482122421265,
      "learning_rate": 4.668482063477118e-05,
      "loss": 0.1059,
      "step": 190
    },
    {
      "epoch": 0.5101373446697187,
      "grad_norm": 0.4153869152069092,
      "learning_rate": 4.6512268471427745e-05,
      "loss": 0.0983,
      "step": 195
    },
    {
      "epoch": 0.5232177894048398,
      "grad_norm": 0.27493923902511597,
      "learning_rate": 4.6335674739728055e-05,
      "loss": 0.0924,
      "step": 200
    },
    {
      "epoch": 0.5362982341399608,
      "grad_norm": 0.29394564032554626,
      "learning_rate": 4.615507261681651e-05,
      "loss": 0.1039,
      "step": 205
    },
    {
      "epoch": 0.5493786788750817,
      "grad_norm": 0.3845468759536743,
      "learning_rate": 4.597049603290491e-05,
      "loss": 0.092,
      "step": 210
    },
    {
      "epoch": 0.5624591236102028,
      "grad_norm": 0.2907315194606781,
      "learning_rate": 4.578197966489781e-05,
      "loss": 0.0949,
      "step": 215
    },
    {
      "epoch": 0.5755395683453237,
      "grad_norm": 0.808944821357727,
      "learning_rate": 4.5589558929877736e-05,
      "loss": 0.0977,
      "step": 220
    },
    {
      "epoch": 0.5886200130804448,
      "grad_norm": 0.26377207040786743,
      "learning_rate": 4.5393269978451234e-05,
      "loss": 0.0997,
      "step": 225
    },
    {
      "epoch": 0.6017004578155657,
      "grad_norm": 0.2556785047054291,
      "learning_rate": 4.519314968795722e-05,
      "loss": 0.0915,
      "step": 230
    },
    {
      "epoch": 0.6147809025506867,
      "grad_norm": 0.23954512178897858,
      "learning_rate": 4.4989235655538654e-05,
      "loss": 0.096,
      "step": 235
    },
    {
      "epoch": 0.6278613472858077,
      "grad_norm": 0.42546361684799194,
      "learning_rate": 4.478156619107912e-05,
      "loss": 0.0972,
      "step": 240
    },
    {
      "epoch": 0.6409417920209287,
      "grad_norm": 0.24013617634773254,
      "learning_rate": 4.457018031000545e-05,
      "loss": 0.0994,
      "step": 245
    },
    {
      "epoch": 0.6540222367560498,
      "grad_norm": 0.8975712060928345,
      "learning_rate": 4.435511772595773e-05,
      "loss": 0.1001,
      "step": 250
    },
    {
      "epoch": 0.6671026814911707,
      "grad_norm": 0.7512338757514954,
      "learning_rate": 4.4136418843328244e-05,
      "loss": 0.0986,
      "step": 255
    },
    {
      "epoch": 0.6801831262262917,
      "grad_norm": 1.408406376838684,
      "learning_rate": 4.39141247496706e-05,
      "loss": 0.1025,
      "step": 260
    },
    {
      "epoch": 0.6932635709614127,
      "grad_norm": 1.1938776969909668,
      "learning_rate": 4.3688277207980446e-05,
      "loss": 0.1018,
      "step": 265
    },
    {
      "epoch": 0.7063440156965337,
      "grad_norm": 0.9875859618186951,
      "learning_rate": 4.345891864884937e-05,
      "loss": 0.1001,
      "step": 270
    },
    {
      "epoch": 0.7194244604316546,
      "grad_norm": 0.5793933272361755,
      "learning_rate": 4.322609216249336e-05,
      "loss": 0.0955,
      "step": 275
    },
    {
      "epoch": 0.7325049051667757,
      "grad_norm": 0.5160239338874817,
      "learning_rate": 4.2989841490657325e-05,
      "loss": 0.0912,
      "step": 280
    },
    {
      "epoch": 0.7455853499018966,
      "grad_norm": 0.3482341170310974,
      "learning_rate": 4.27502110183972e-05,
      "loss": 0.0936,
      "step": 285
    },
    {
      "epoch": 0.7586657946370177,
      "grad_norm": 0.7827405333518982,
      "learning_rate": 4.250724576574122e-05,
      "loss": 0.0922,
      "step": 290
    },
    {
      "epoch": 0.7717462393721386,
      "grad_norm": 1.0144151449203491,
      "learning_rate": 4.226099137923186e-05,
      "loss": 0.1114,
      "step": 295
    },
    {
      "epoch": 0.7848266841072596,
      "grad_norm": 0.47363582253456116,
      "learning_rate": 4.201149412335015e-05,
      "loss": 0.0942,
      "step": 300
    },
    {
      "epoch": 0.7979071288423807,
      "grad_norm": 0.4187525510787964,
      "learning_rate": 4.1758800871823756e-05,
      "loss": 0.1026,
      "step": 305
    },
    {
      "epoch": 0.8109875735775016,
      "grad_norm": 1.1564923524856567,
      "learning_rate": 4.150295909882077e-05,
      "loss": 0.1006,
      "step": 310
    },
    {
      "epoch": 0.8240680183126227,
      "grad_norm": 0.3445660471916199,
      "learning_rate": 4.124401687003057e-05,
      "loss": 0.0967,
      "step": 315
    },
    {
      "epoch": 0.8371484630477436,
      "grad_norm": 0.48739221692085266,
      "learning_rate": 4.098202283363356e-05,
      "loss": 0.084,
      "step": 320
    },
    {
      "epoch": 0.8502289077828646,
      "grad_norm": 0.5302808284759521,
      "learning_rate": 4.071702621116158e-05,
      "loss": 0.0907,
      "step": 325
    },
    {
      "epoch": 0.8633093525179856,
      "grad_norm": 0.3211367130279541,
      "learning_rate": 4.0449076788250446e-05,
      "loss": 0.0891,
      "step": 330
    },
    {
      "epoch": 0.8763897972531066,
      "grad_norm": 1.046342134475708,
      "learning_rate": 4.0178224905286635e-05,
      "loss": 0.0978,
      "step": 335
    },
    {
      "epoch": 0.8894702419882276,
      "grad_norm": 0.9398048520088196,
      "learning_rate": 3.990452144794966e-05,
      "loss": 0.0766,
      "step": 340
    },
    {
      "epoch": 0.9025506867233486,
      "grad_norm": 0.5235814452171326,
      "learning_rate": 3.96280178376521e-05,
      "loss": 0.0953,
      "step": 345
    },
    {
      "epoch": 0.9156311314584696,
      "grad_norm": 0.7244617342948914,
      "learning_rate": 3.934876602187886e-05,
      "loss": 0.0953,
      "step": 350
    },
    {
      "epoch": 0.9287115761935906,
      "grad_norm": 0.33467045426368713,
      "learning_rate": 3.9066818464427676e-05,
      "loss": 0.0962,
      "step": 355
    },
    {
      "epoch": 0.9417920209287116,
      "grad_norm": 1.0760302543640137,
      "learning_rate": 3.878222813555261e-05,
      "loss": 0.0892,
      "step": 360
    },
    {
      "epoch": 0.9548724656638325,
      "grad_norm": 0.3034672439098358,
      "learning_rate": 3.849504850201237e-05,
      "loss": 0.0966,
      "step": 365
    },
    {
      "epoch": 0.9679529103989536,
      "grad_norm": 0.5832273960113525,
      "learning_rate": 3.820533351702538e-05,
      "loss": 0.0921,
      "step": 370
    },
    {
      "epoch": 0.9810333551340745,
      "grad_norm": 0.5002449750900269,
      "learning_rate": 3.791313761013343e-05,
      "loss": 0.0933,
      "step": 375
    },
    {
      "epoch": 0.9941137998691956,
      "grad_norm": 0.5006173253059387,
      "learning_rate": 3.761851567697583e-05,
      "loss": 0.0869,
      "step": 380
    },
    {
      "epoch": 1.0071942446043165,
      "grad_norm": 0.5968994498252869,
      "learning_rate": 3.732152306897607e-05,
      "loss": 0.0815,
      "step": 385
    },
    {
      "epoch": 1.0202746893394374,
      "grad_norm": 0.24202778935432434,
      "learning_rate": 3.702221558294274e-05,
      "loss": 0.0848,
      "step": 390
    },
    {
      "epoch": 1.0333551340745586,
      "grad_norm": 0.9544261693954468,
      "learning_rate": 3.6720649450586884e-05,
      "loss": 0.0925,
      "step": 395
    },
    {
      "epoch": 1.0464355788096795,
      "grad_norm": 0.34741780161857605,
      "learning_rate": 3.641688132795757e-05,
      "loss": 0.0912,
      "step": 400
    },
    {
      "epoch": 1.0595160235448005,
      "grad_norm": 0.36272433400154114,
      "learning_rate": 3.611096828479773e-05,
      "loss": 0.0961,
      "step": 405
    },
    {
      "epoch": 1.0725964682799216,
      "grad_norm": 0.3128516674041748,
      "learning_rate": 3.5802967793822384e-05,
      "loss": 0.0919,
      "step": 410
    },
    {
      "epoch": 1.0856769130150425,
      "grad_norm": 0.2931552827358246,
      "learning_rate": 3.549293771992104e-05,
      "loss": 0.0974,
      "step": 415
    },
    {
      "epoch": 1.0987573577501635,
      "grad_norm": 0.8473382592201233,
      "learning_rate": 3.518093630928644e-05,
      "loss": 0.1002,
      "step": 420
    },
    {
      "epoch": 1.1118378024852844,
      "grad_norm": 0.18603630363941193,
      "learning_rate": 3.486702217847176e-05,
      "loss": 0.0906,
      "step": 425
    },
    {
      "epoch": 1.1249182472204056,
      "grad_norm": 0.4289111793041229,
      "learning_rate": 3.455125430337809e-05,
      "loss": 0.0888,
      "step": 430
    },
    {
      "epoch": 1.1379986919555265,
      "grad_norm": 0.9432826042175293,
      "learning_rate": 3.4233692008174493e-05,
      "loss": 0.095,
      "step": 435
    },
    {
      "epoch": 1.1510791366906474,
      "grad_norm": 0.535589337348938,
      "learning_rate": 3.3914394954152636e-05,
      "loss": 0.0897,
      "step": 440
    },
    {
      "epoch": 1.1641595814257686,
      "grad_norm": 0.3303111493587494,
      "learning_rate": 3.359342312851802e-05,
      "loss": 0.0987,
      "step": 445
    },
    {
      "epoch": 1.1772400261608895,
      "grad_norm": 0.7820762395858765,
      "learning_rate": 3.327083683312004e-05,
      "loss": 0.0866,
      "step": 450
    },
    {
      "epoch": 1.1903204708960105,
      "grad_norm": 0.31963762640953064,
      "learning_rate": 3.294669667312295e-05,
      "loss": 0.0864,
      "step": 455
    },
    {
      "epoch": 1.2034009156311314,
      "grad_norm": 0.23728127777576447,
      "learning_rate": 3.262106354561973e-05,
      "loss": 0.089,
      "step": 460
    },
    {
      "epoch": 1.2164813603662525,
      "grad_norm": 0.43556031584739685,
      "learning_rate": 3.2293998628191246e-05,
      "loss": 0.0787,
      "step": 465
    },
    {
      "epoch": 1.2295618051013735,
      "grad_norm": 0.46616122126579285,
      "learning_rate": 3.196556336741261e-05,
      "loss": 0.0871,
      "step": 470
    },
    {
      "epoch": 1.2426422498364944,
      "grad_norm": 0.44181832671165466,
      "learning_rate": 3.163581946730909e-05,
      "loss": 0.0915,
      "step": 475
    },
    {
      "epoch": 1.2557226945716153,
      "grad_norm": 0.8202056884765625,
      "learning_rate": 3.130482887776356e-05,
      "loss": 0.0878,
      "step": 480
    },
    {
      "epoch": 1.2688031393067365,
      "grad_norm": 0.2390565276145935,
      "learning_rate": 3.097265378287784e-05,
      "loss": 0.0831,
      "step": 485
    },
    {
      "epoch": 1.2818835840418574,
      "grad_norm": 0.38188666105270386,
      "learning_rate": 3.063935658928998e-05,
      "loss": 0.0818,
      "step": 490
    },
    {
      "epoch": 1.2949640287769784,
      "grad_norm": 0.5214235186576843,
      "learning_rate": 3.0304999914449773e-05,
      "loss": 0.0832,
      "step": 495
    },
    {
      "epoch": 1.3080444735120995,
      "grad_norm": 0.29232659935951233,
      "learning_rate": 2.996964657485463e-05,
      "loss": 0.0775,
      "step": 500
    },
    {
      "epoch": 1.3211249182472204,
      "grad_norm": 0.2689616084098816,
      "learning_rate": 2.9633359574248075e-05,
      "loss": 0.0798,
      "step": 505
    },
    {
      "epoch": 1.3342053629823414,
      "grad_norm": 1.3930453062057495,
      "learning_rate": 2.9296202091783072e-05,
      "loss": 0.094,
      "step": 510
    },
    {
      "epoch": 1.3472858077174623,
      "grad_norm": 0.6868529915809631,
      "learning_rate": 2.895823747015237e-05,
      "loss": 0.0859,
      "step": 515
    },
    {
      "epoch": 1.3603662524525835,
      "grad_norm": 0.5896928310394287,
      "learning_rate": 2.8619529203688163e-05,
      "loss": 0.0856,
      "step": 520
    },
    {
      "epoch": 1.3734466971877044,
      "grad_norm": 0.4728444516658783,
      "learning_rate": 2.8280140926433192e-05,
      "loss": 0.0826,
      "step": 525
    },
    {
      "epoch": 1.3865271419228253,
      "grad_norm": 0.19904707372188568,
      "learning_rate": 2.7940136400185695e-05,
      "loss": 0.0854,
      "step": 530
    },
    {
      "epoch": 1.3996075866579463,
      "grad_norm": 0.2343883216381073,
      "learning_rate": 2.7599579502520295e-05,
      "loss": 0.0853,
      "step": 535
    },
    {
      "epoch": 1.4126880313930674,
      "grad_norm": 0.360029935836792,
      "learning_rate": 2.7258534214787108e-05,
      "loss": 0.0808,
      "step": 540
    },
    {
      "epoch": 1.4257684761281884,
      "grad_norm": 0.3587040603160858,
      "learning_rate": 2.6917064610091423e-05,
      "loss": 0.0865,
      "step": 545
    },
    {
      "epoch": 1.4388489208633093,
      "grad_norm": 0.543120265007019,
      "learning_rate": 2.6575234841256137e-05,
      "loss": 0.0824,
      "step": 550
    },
    {
      "epoch": 1.4519293655984304,
      "grad_norm": 0.29821664094924927,
      "learning_rate": 2.6233109128769136e-05,
      "loss": 0.0844,
      "step": 555
    },
    {
      "epoch": 1.4650098103335514,
      "grad_norm": 0.552946925163269,
      "learning_rate": 2.5890751748718055e-05,
      "loss": 0.0888,
      "step": 560
    },
    {
      "epoch": 1.4780902550686723,
      "grad_norm": 0.9959383010864258,
      "learning_rate": 2.5548227020714534e-05,
      "loss": 0.0855,
      "step": 565
    },
    {
      "epoch": 1.4911706998037935,
      "grad_norm": 1.0566694736480713,
      "learning_rate": 2.5205599295810338e-05,
      "loss": 0.0899,
      "step": 570
    },
    {
      "epoch": 1.5042511445389142,
      "grad_norm": 0.2874617576599121,
      "learning_rate": 2.486293294440755e-05,
      "loss": 0.0976,
      "step": 575
    },
    {
      "epoch": 1.5173315892740353,
      "grad_norm": 0.34568533301353455,
      "learning_rate": 2.452029234416509e-05,
      "loss": 0.0855,
      "step": 580
    },
    {
      "epoch": 1.5304120340091563,
      "grad_norm": 0.5012521147727966,
      "learning_rate": 2.4177741867903967e-05,
      "loss": 0.0778,
      "step": 585
    },
    {
      "epoch": 1.5434924787442772,
      "grad_norm": 0.7582708597183228,
      "learning_rate": 2.3835345871513333e-05,
      "loss": 0.0816,
      "step": 590
    },
    {
      "epoch": 1.5565729234793984,
      "grad_norm": 0.9356819987297058,
      "learning_rate": 2.349316868185978e-05,
      "loss": 0.0849,
      "step": 595
    },
    {
      "epoch": 1.5696533682145193,
      "grad_norm": 1.5056514739990234,
      "learning_rate": 2.315127458470212e-05,
      "loss": 0.092,
      "step": 600
    },
    {
      "epoch": 1.5827338129496402,
      "grad_norm": 0.5051658153533936,
      "learning_rate": 2.2809727812613767e-05,
      "loss": 0.0817,
      "step": 605
    },
    {
      "epoch": 1.5958142576847614,
      "grad_norm": 0.22831106185913086,
      "learning_rate": 2.246859253291524e-05,
      "loss": 0.078,
      "step": 610
    },
    {
      "epoch": 1.6088947024198823,
      "grad_norm": 0.4691559374332428,
      "learning_rate": 2.2127932835618897e-05,
      "loss": 0.0923,
      "step": 615
    },
    {
      "epoch": 1.6219751471550032,
      "grad_norm": 0.26445847749710083,
      "learning_rate": 2.178781272138809e-05,
      "loss": 0.0846,
      "step": 620
    },
    {
      "epoch": 1.6350555918901244,
      "grad_norm": 0.7524809241294861,
      "learning_rate": 2.144829608951327e-05,
      "loss": 0.0927,
      "step": 625
    },
    {
      "epoch": 1.648136036625245,
      "grad_norm": 0.6294331550598145,
      "learning_rate": 2.1109446725907003e-05,
      "loss": 0.0879,
      "step": 630
    },
    {
      "epoch": 1.6612164813603663,
      "grad_norm": 0.7658856511116028,
      "learning_rate": 2.0771328291120334e-05,
      "loss": 0.0863,
      "step": 635
    },
    {
      "epoch": 1.6742969260954872,
      "grad_norm": 0.3641132414340973,
      "learning_rate": 2.0434004308382763e-05,
      "loss": 0.0871,
      "step": 640
    },
    {
      "epoch": 1.6873773708306081,
      "grad_norm": 0.47723883390426636,
      "learning_rate": 2.0097538151667886e-05,
      "loss": 0.0844,
      "step": 645
    },
    {
      "epoch": 1.7004578155657293,
      "grad_norm": 0.28920456767082214,
      "learning_rate": 1.9761993033787205e-05,
      "loss": 0.0705,
      "step": 650
    },
    {
      "epoch": 1.7135382603008502,
      "grad_norm": 0.28731486201286316,
      "learning_rate": 1.9427431994514178e-05,
      "loss": 0.0936,
      "step": 655
    },
    {
      "epoch": 1.7266187050359711,
      "grad_norm": 0.6041886806488037,
      "learning_rate": 1.909391788874069e-05,
      "loss": 0.0891,
      "step": 660
    },
    {
      "epoch": 1.7396991497710923,
      "grad_norm": 0.626645565032959,
      "learning_rate": 1.876151337466843e-05,
      "loss": 0.0807,
      "step": 665
    },
    {
      "epoch": 1.7527795945062132,
      "grad_norm": 0.5039736032485962,
      "learning_rate": 1.8430280902037062e-05,
      "loss": 0.0877,
      "step": 670
    },
    {
      "epoch": 1.7658600392413342,
      "grad_norm": 0.33579063415527344,
      "learning_rate": 1.8100282700391616e-05,
      "loss": 0.0914,
      "step": 675
    },
    {
      "epoch": 1.7789404839764553,
      "grad_norm": 0.3189871311187744,
      "learning_rate": 1.7771580767391314e-05,
      "loss": 0.0882,
      "step": 680
    },
    {
      "epoch": 1.792020928711576,
      "grad_norm": 0.9598245620727539,
      "learning_rate": 1.7444236857161835e-05,
      "loss": 0.0849,
      "step": 685
    },
    {
      "epoch": 1.8051013734466972,
      "grad_norm": 0.8158779740333557,
      "learning_rate": 1.7118312468693438e-05,
      "loss": 0.0949,
      "step": 690
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.32018691301345825,
      "learning_rate": 1.6793868834286986e-05,
      "loss": 0.0904,
      "step": 695
    },
    {
      "epoch": 1.831262262916939,
      "grad_norm": 0.21929039061069489,
      "learning_rate": 1.647096690805001e-05,
      "loss": 0.0886,
      "step": 700
    },
    {
      "epoch": 1.8443427076520602,
      "grad_norm": 0.2277696281671524,
      "learning_rate": 1.614966735444519e-05,
      "loss": 0.089,
      "step": 705
    },
    {
      "epoch": 1.8574231523871811,
      "grad_norm": 0.27221882343292236,
      "learning_rate": 1.5830030536893065e-05,
      "loss": 0.0937,
      "step": 710
    },
    {
      "epoch": 1.870503597122302,
      "grad_norm": 0.29575788974761963,
      "learning_rate": 1.551211650643144e-05,
      "loss": 0.0869,
      "step": 715
    },
    {
      "epoch": 1.8835840418574232,
      "grad_norm": 0.3709608018398285,
      "learning_rate": 1.5195984990433438e-05,
      "loss": 0.0888,
      "step": 720
    },
    {
      "epoch": 1.8966644865925442,
      "grad_norm": 0.5661364197731018,
      "learning_rate": 1.4881695381386324e-05,
      "loss": 0.0919,
      "step": 725
    },
    {
      "epoch": 1.909744931327665,
      "grad_norm": 0.3582221567630768,
      "learning_rate": 1.4569306725733312e-05,
      "loss": 0.075,
      "step": 730
    },
    {
      "epoch": 1.9228253760627863,
      "grad_norm": 0.942704975605011,
      "learning_rate": 1.4258877712780333e-05,
      "loss": 0.0837,
      "step": 735
    },
    {
      "epoch": 1.9359058207979072,
      "grad_norm": 0.803612232208252,
      "learning_rate": 1.3950466663669915e-05,
      "loss": 0.0915,
      "step": 740
    },
    {
      "epoch": 1.9489862655330281,
      "grad_norm": 0.6440640687942505,
      "learning_rate": 1.3644131520424241e-05,
      "loss": 0.0775,
      "step": 745
    },
    {
      "epoch": 1.9620667102681493,
      "grad_norm": 0.5920970439910889,
      "learning_rate": 1.3339929835059391e-05,
      "loss": 0.0785,
      "step": 750
    },
    {
      "epoch": 1.97514715500327,
      "grad_norm": 0.7835463285446167,
      "learning_rate": 1.3037918758772943e-05,
      "loss": 0.0867,
      "step": 755
    },
    {
      "epoch": 1.9882275997383911,
      "grad_norm": 0.3500520884990692,
      "learning_rate": 1.2738155031206772e-05,
      "loss": 0.0808,
      "step": 760
    },
    {
      "epoch": 2.0013080444735123,
      "grad_norm": 0.5244514346122742,
      "learning_rate": 1.2440694969787262e-05,
      "loss": 0.0941,
      "step": 765
    },
    {
      "epoch": 2.014388489208633,
      "grad_norm": 0.5884719491004944,
      "learning_rate": 1.2145594459144744e-05,
      "loss": 0.0789,
      "step": 770
    },
    {
      "epoch": 2.027468933943754,
      "grad_norm": 0.30168700218200684,
      "learning_rate": 1.1852908940614355e-05,
      "loss": 0.0865,
      "step": 775
    },
    {
      "epoch": 2.040549378678875,
      "grad_norm": 1.2228389978408813,
      "learning_rate": 1.1562693401820093e-05,
      "loss": 0.0856,
      "step": 780
    },
    {
      "epoch": 2.053629823413996,
      "grad_norm": 0.24984878301620483,
      "learning_rate": 1.1275002366344155e-05,
      "loss": 0.0855,
      "step": 785
    },
    {
      "epoch": 2.066710268149117,
      "grad_norm": 0.26588699221611023,
      "learning_rate": 1.0989889883483414e-05,
      "loss": 0.0896,
      "step": 790
    },
    {
      "epoch": 2.079790712884238,
      "grad_norm": 0.49111849069595337,
      "learning_rate": 1.070740951809508e-05,
      "loss": 0.0791,
      "step": 795
    },
    {
      "epoch": 2.092871157619359,
      "grad_norm": 0.7042036652565002,
      "learning_rate": 1.0427614340533293e-05,
      "loss": 0.0912,
      "step": 800
    },
    {
      "epoch": 2.10595160235448,
      "grad_norm": 0.2668745815753937,
      "learning_rate": 1.0150556916678632e-05,
      "loss": 0.0766,
      "step": 805
    },
    {
      "epoch": 2.119032047089601,
      "grad_norm": 0.2721465528011322,
      "learning_rate": 9.876289298062477e-06,
      "loss": 0.0825,
      "step": 810
    },
    {
      "epoch": 2.132112491824722,
      "grad_norm": 0.6131836771965027,
      "learning_rate": 9.604863012087903e-06,
      "loss": 0.0897,
      "step": 815
    },
    {
      "epoch": 2.145192936559843,
      "grad_norm": 0.6942887902259827,
      "learning_rate": 9.336329052349087e-06,
      "loss": 0.0838,
      "step": 820
    },
    {
      "epoch": 2.158273381294964,
      "grad_norm": 0.2673965096473694,
      "learning_rate": 9.070737869051044e-06,
      "loss": 0.0776,
      "step": 825
    },
    {
      "epoch": 2.171353826030085,
      "grad_norm": 0.28121083974838257,
      "learning_rate": 8.808139359531332e-06,
      "loss": 0.0902,
      "step": 830
    },
    {
      "epoch": 2.1844342707652062,
      "grad_norm": 1.1179462671279907,
      "learning_rate": 8.548582858885786e-06,
      "loss": 0.0886,
      "step": 835
    },
    {
      "epoch": 2.197514715500327,
      "grad_norm": 0.5652133822441101,
      "learning_rate": 8.292117130699767e-06,
      "loss": 0.0836,
      "step": 840
    },
    {
      "epoch": 2.210595160235448,
      "grad_norm": 0.3791660666465759,
      "learning_rate": 8.038790357886783e-06,
      "loss": 0.084,
      "step": 845
    },
    {
      "epoch": 2.223675604970569,
      "grad_norm": 0.38121914863586426,
      "learning_rate": 7.78865013363629e-06,
      "loss": 0.082,
      "step": 850
    },
    {
      "epoch": 2.23675604970569,
      "grad_norm": 0.44388285279273987,
      "learning_rate": 7.541743452472194e-06,
      "loss": 0.08,
      "step": 855
    },
    {
      "epoch": 2.249836494440811,
      "grad_norm": 0.9325562119483948,
      "learning_rate": 7.298116701423874e-06,
      "loss": 0.0884,
      "step": 860
    },
    {
      "epoch": 2.262916939175932,
      "grad_norm": 0.8526800870895386,
      "learning_rate": 7.0578156513113224e-06,
      "loss": 0.0883,
      "step": 865
    },
    {
      "epoch": 2.275997383911053,
      "grad_norm": 0.7581974864006042,
      "learning_rate": 6.820885448146042e-06,
      "loss": 0.0815,
      "step": 870
    },
    {
      "epoch": 2.289077828646174,
      "grad_norm": 0.366294264793396,
      "learning_rate": 6.587370604649373e-06,
      "loss": 0.0788,
      "step": 875
    },
    {
      "epoch": 2.302158273381295,
      "grad_norm": 0.3596220910549164,
      "learning_rate": 6.357314991889756e-06,
      "loss": 0.0797,
      "step": 880
    },
    {
      "epoch": 2.315238718116416,
      "grad_norm": 0.3465404212474823,
      "learning_rate": 6.130761831040521e-06,
      "loss": 0.0748,
      "step": 885
    },
    {
      "epoch": 2.328319162851537,
      "grad_norm": 0.2586510479450226,
      "learning_rate": 5.907753685259865e-06,
      "loss": 0.0847,
      "step": 890
    },
    {
      "epoch": 2.341399607586658,
      "grad_norm": 0.30897095799446106,
      "learning_rate": 5.688332451694356e-06,
      "loss": 0.0804,
      "step": 895
    },
    {
      "epoch": 2.354480052321779,
      "grad_norm": 0.34477776288986206,
      "learning_rate": 5.472539353607611e-06,
      "loss": 0.0772,
      "step": 900
    }
  ],
  "logging_steps": 5,
  "max_steps": 1146,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "total_flos": 5.6584589144467046e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
